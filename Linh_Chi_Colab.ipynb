{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnPoqRcE4oy2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pathlib import Path\n",
    "from scipy.stats import iqr\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# the model\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "JcM0prDI_u04",
    "outputId": "3769d899-f83a-4ae0-ac1f-31b020215c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=1827a182f365c5b2fea6590db71669bcbd41645c82abeed3b5612420c6a99ebf\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Gen RAM Free: 12.6 GB  | Proc size: 490.9 MB\n",
      "GPU RAM Free: 11372MB | Used: 69MB | Util   1% | Total 11441MB\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "2UFe6Zu5_3P2",
    "outputId": "317c8fe9-c725-4a5b-fe23-73575d792dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "049Y6_hf5Uuv"
   },
   "outputs": [],
   "source": [
    "#Import files\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GX7Csmk4oy6"
   },
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col='building_id')\n",
    "selected_features = ['foundation_type', \n",
    "                     'area_percentage', \n",
    "                     'height_percentage',\n",
    "                     'count_floors_pre_eq',\n",
    "                     'land_surface_condition',\n",
    "                     'has_superstructure_cement_mortar_stone']\n",
    "train_values_subset = train_values[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGSSeGNL4oy8"
   },
   "outputs": [],
   "source": [
    "train_values_subset = pd.get_dummies(train_values_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ButPedH04oy-"
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "## RBF kernels\n",
    "pipe_steps = [('scaler', StandardScaler()), ('pca', PCA()), ('SupVM', SVC(kernel='rbf'))]\n",
    "pipe = Pipeline(pipe_steps)\n",
    "param_grid = {'pca__n_components': [2],\n",
    "              'SupVM__C': [0.1, 0.5, 1, 10, 30, 40, 50, 70, 100, 500, 1000],\n",
    "              'SupVM__gamma': [0.001, 0.005, 0.01, 0.05, 0.07, 0.1, 0.5, 1, 5, 10, 50],\n",
    "             }\n",
    "print('Start fitting training data')\n",
    "\n",
    "for num_cv in tqdm(range(4, 7)):     \n",
    "    gs = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    gs.fit(train_values_subset, train_labels.values.ravel())\n",
    "    print(\"Best fit parameter for %d fold CV\" % num_cv, gs.best_params_)\n",
    "\n",
    "    #Evaluate the model\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    in_sample_preds = gs.predict(train_values_subset)\n",
    "    f1_score(train_labels, in_sample_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNGSlctf4ozC"
   },
   "outputs": [],
   "source": [
    "#Read values then output Results\n",
    "test_values = pd.read_csv('test_values.csv', index_col='building_id')\n",
    "test_values_subset = test_values[selected_features]\n",
    "test_values_subset = pd.get_dummies(test_values_subset)\n",
    "predictions = gs.predict(test_values_subset)\n",
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission.head()\n",
    "my_submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Linh_Chi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
